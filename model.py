# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/148ROUmcAGHFYkKLdZ1ReGHvEWYdG6e9_
"""

from google.colab import files
uploaded = files.upload()

#!pip install seaborn opencv-python-headless
import numpy as np
import matplotlib.pyplot as plt
import os
import zipfile
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
# Define dataset paths
zip_path = '/content/Pancreas (1).zip'
unzip_dir = '/content/Pancreas (1)'

# Unzip dataset if not already extracted
if not os.path.exists(unzip_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(unzip_dir)

img_size = 224
batch_size = 32
train_path = '/content/Pancreas (1)'
epochs = 15

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_gen = datagen.flow_from_directory(
    train_path,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='binary',
    subset='training',
    shuffle=True
)

val_gen = datagen.flow_from_directory(
    train_path,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='binary',
    subset='validation',
    shuffle=False
)

# ==================== 5. Build CNN Model using VGG16 ====================
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))
for layer in base_model.layers:
    layer.trainable = False  # Freeze pretrained layers

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
preds = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=preds)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# ==================== 6. Train the Model ====================
checkpoint = ModelCheckpoint('pancreas_cnn_model.h5', monitor='val_accuracy', save_best_only=True)

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=epochs,
    callbacks=[checkpoint]
)

# ==================== 7. Plot Accuracy and Loss ====================
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.legend(); plt.title('Accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title('Loss')
plt.show()

# ==================== 8. Classification Report ====================
val_gen.reset()
preds = model.predict(val_gen)
preds_class = (preds > 0.5).astype(int)

print("Classification Report:\n", classification_report(val_gen.classes, preds_class))
print("Confusion Matrix:\n")
sns.heatmap(confusion_matrix(val_gen.classes, preds_class), annot=True, fmt='d', cmap='Blues')
plt.show()

# ==================== 9. Generate Grad-CAM Heatmap ====================
def get_gradcam_heatmap(img_array, model, last_conv_layer_name='block5_conv3'):
    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_output, predictions = grad_model(img_array)
        loss = predictions[:, 0]

    grads = tape.gradient(loss, conv_output)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_output = conv_output[0]
    heatmap = conv_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    return heatmap.numpy()

# ==================== 10. Show Heatmap and Affected Area % ====================
def display_heatmap_on_image(img_path, model):
    img = cv2.imread(img_path)
    img_resized = cv2.resize(img, (img_size, img_size))
    img_array = np.expand_dims(img_resized / 255.0, axis=0)

    heatmap = get_gradcam_heatmap(img_array, model)
    heatmap = cv2.resize(heatmap, (img_size, img_size))
    heatmap_colored = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)
    superimposed_img = heatmap_colored * 0.4 + img_resized

    # Estimate Affected Area %
    threshold = 0.4
    affected_area = np.sum(heatmap > threshold) / (img_size * img_size) * 100

    plt.figure(figsize=(12,6))
    plt.subplot(1,2,1); plt.imshow(img_resized); plt.title("Original Image")
    plt.subplot(1,2,2); plt.imshow(superimposed_img.astype('uint8'))
    plt.title(f"Grad-CAM Heatmap | Affected Area: {affected_area:.2f}%")
    plt.axis('off')
    plt.show()
    return affected_area

from sklearn.metrics import accuracy_score

true_labels = val_gen.classes
accuracy = accuracy_score(true_labels, preds_class)
print(f"\n✅ Overall Validation Accuracy (manual): {accuracy * 100:.2f}%")

# ✅ Save the final trained model manually
model.save('pancreas_cnn_model.h5')
print("✅ Model saved successfully as 'pancreas_cnn_model.h5'")

from google.colab import files
files.download('pancreas_cnn_model.h5')